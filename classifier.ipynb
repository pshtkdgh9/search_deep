{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65562f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\netdb\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from tensorflow) (0.25.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from tensorflow) (3.20.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from tensorflow) (1.44.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.6.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\netdb\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3e6cb7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "df = pd.read_csv('./bigdata_num.csv', encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14729231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df3be1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import csv\n",
    "\n",
    "# 실험 결과를 재현하기 위해 난수 발생패턴을 고정시키는 np.random.seed()함수값을 설정\n",
    "np.random.seed(333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73facbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "RND_MEAN = 0  # 평균\n",
    "RND_STD = 0.003  # 표준편차\n",
    "Learning_rate = 0.003  # 학습률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e96f720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_classification_exec(epoch_count=10, mb_size=10, report=1,train_rate = 0.8):\n",
    "    binary_load_dataset()\n",
    "    init_model()\n",
    "    train_and_test(epoch_count, mb_size, report, train_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "076d08a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 받기 > 버퍼로 옮겨주기 > np.array()로 감싸주기\n",
    "def binary_load_dataset():\n",
    "    with open('./bigdata_num.csv', encoding=\"utf-8-sig\") as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        next(csvreader, None)\n",
    "        rows = []\n",
    "        for row in csvreader:\n",
    "            rows.append(row)\n",
    "            \n",
    "    global data, input_cnt, output_cnt\n",
    "    input_cnt, output_cnt = 8, 1  # 독립변수, 종속변수독립변수, 종속변수\n",
    "    data = np.asarray(rows, dtype='float32') # 배열 구조로 변환하는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "147540c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    global weight, bias, input_cnt, output_cnt\n",
    "    weight = np.random.normal(RND_MEAN, RND_STD,[input_cnt, output_cnt])  \n",
    "    # normal 메서드 :  (mean, sd, shape)\n",
    "    \n",
    "    bias = np.zeros([output_cnt])\n",
    "    # weight 가중치 행렬은 [8,1] , bias 편향 벡터는 [1]형태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2a6c50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(epoch_count, mb_size, report, train_rate):\n",
    "    step_count = arrange_data(mb_size, train_rate)\n",
    "    test_x, test_y = get_test_data()\n",
    "\n",
    "    for epoch in range(epoch_count):\n",
    "        losses, accs = [], []\n",
    "\n",
    "        for n in range(step_count):\n",
    "            train_x, train_y = get_train_data(mb_size, n)\n",
    "            loss, acc = run_train(train_x, train_y)\n",
    "            losses.append(loss)\n",
    "            accs.append(acc)\n",
    "\n",
    "        if report > 0 and (epoch + 1) % report == 0:\n",
    "            acc = run_test(test_x, test_y)\n",
    "            print(f'Epoch {epoch+1}: loss={np.mean(losses):5.3f}, accuracy={np.mean(accs):5.3f}/{acc:5.3f}')\n",
    "            \n",
    "    final_acc = run_test(test_x, test_y)\n",
    "    print(f'\\nFinal Test: final accuracy = {final_acc:5.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71f1d38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrange_data(mb_size, train_rate):\n",
    "    global data, shuffle_map, test_begin_idx\n",
    "\n",
    "    shuffle_map = np.arange(data.shape[0])\n",
    "    np.random.shuffle(shuffle_map)\n",
    "\n",
    "    step_count = int(data.shape[0] * train_rate) // mb_size\n",
    "\n",
    "    test_begin_idx = step_count * mb_size\n",
    "\n",
    "    return step_count\n",
    "\n",
    "\n",
    "def get_test_data():\n",
    "    global data, shuffle_map, test_begin_idx, output_cnt\n",
    "\n",
    "    test_data = data[shuffle_map[test_begin_idx:]]\n",
    "\n",
    "    return test_data[:, :-output_cnt], test_data[:, -output_cnt:]\n",
    "\n",
    "\n",
    "def get_train_data(mb_size, nth):\n",
    "    global data, shuffle_map, test_begin_idx, output_cnt\n",
    "\n",
    "    if nth == 0:\n",
    "        np.random.shuffle(shuffle_map[:test_begin_idx])\n",
    "\n",
    "    train_data = data[shuffle_map[mb_size * nth:mb_size * (nth + 1)]]\n",
    "\n",
    "    return train_data[:, :-output_cnt], train_data[:, -output_cnt:]\n",
    "    \n",
    "    \n",
    "def run_train(x, y):\n",
    "    output, aux_nn = forward_neuralnet(x)\n",
    "    loss, aux_pp = forward_postproc(output, y)\n",
    "    accuracy = eval_accuracy(output, y)\n",
    "\n",
    "    G_loss = 1.0\n",
    "    G_output = backprop_postproc(G_loss, aux_pp)\n",
    "    backprop_neuralnet(G_output, aux_nn)\n",
    "\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "def run_test(x, y):\n",
    "    output, _ = forward_neuralnet(x)\n",
    "    accuracy = eval_accuracy(output, y)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40514a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_neuralnet(x):  \n",
    "    global weight, bias\n",
    "    output = np.matmul(x, weight) + bias  # y = xw + b\n",
    "    \n",
    "    return output, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de2988bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_cross_entropy_with_logits(z, x):\n",
    "    return relu(x) - x * z + np.log(1 + np.exp(-np.abs(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bd48cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop_neuralnet(G_output, x):  \n",
    "    global weight, bias\n",
    "    g_output_w = x.transpose()\n",
    "\n",
    "    G_w = np.matmul(g_output_w, G_output) \n",
    "    G_b = np.sum(G_output, axis=0)\n",
    "\n",
    "    weight -= Learning_rate * G_w\n",
    "    bias -= Learning_rate * G_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96bb1364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_postproc(output, y):\n",
    "    CEE = sigmoid_cross_entropy_with_logits(y, output)\n",
    "    loss = np.mean(CEE)\n",
    "\n",
    "    return loss, [y, output, CEE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e052b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop_postproc(G_loss, aux):\n",
    "    y, output, entropy = aux\n",
    "    \n",
    "    g_loss_entropy = 1.0 / np.prod(entropy.shape)\n",
    "    g_entropy_output = sigmoid_cross_entropy_with_logits(y, output)    \n",
    "    \n",
    "    G_entropy = g_loss_entropy * G_loss\n",
    "    G_output = g_entropy_output * G_entropy\n",
    "    \n",
    "    return G_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6761ea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_accuracy(output, y):\n",
    "    estimate = np.greater(output, 0)\n",
    "    answer = np.greater(y, 0.5)\n",
    "    correct = np.equal(estimate, answer)\n",
    "\n",
    "    return np.mean(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0ddea31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss=267708712937061072811082121216.000, accuracy=0.997/0.999\n",
      "Epoch 2: loss=1484596432988807147884937434021558451376447712461064241152.000, accuracy=0.999/0.999\n",
      "Epoch 3: loss=4250191803154452937874564718334700957627832654766553186303269923469723581078994849628160.000, accuracy=0.999/0.999\n",
      "Epoch 4: loss=8370679326554694357046277023662395553692666302203094534888613418402972748643399930799415949758675809295442706545246208.000, accuracy=0.999/0.999\n",
      "Epoch 5: loss=6024995605249498963638741234232412095916670859153270729367921551713251168884456019342659097096858905803985559907249389400894414141348377161669541888.000, accuracy=0.999/0.999\n",
      "Epoch 6: loss=32449256287360461727076770341032623828644192865383579390827673638817794413733250590701882582820294190284478778975770983758024943078892171495102624709804857562305691532095878332416.000, accuracy=0.999/0.999\n",
      "Epoch 7: loss=18389104359376870522259887506074230556302020647928737249548464511060263499245117932775479849455944075322417456911698099164969525207824982217881221921535629553606450449937545236650964638141159179248226929737728.000, accuracy=0.999/0.999\n",
      "Epoch 8: loss=112284157012035051029068641178280192157347530655918064588039115539859278276795661538574081713121617159594548536819120543000099704383802643941365073791811036010289400333249442974759830101117667073413114859309014406635969043760618244407296.000, accuracy=0.999/0.999\n",
      "Epoch 9: loss=34756988968216260824302955920900967576640357376042317887453518275339536090695733286943739603896515902655937425495102570338961772028094249440702869555682055258326743629807318570350925662882732953296026732976513286034602347549310063901083320304572783629658421907685376.000, accuracy=0.999/0.999\n",
      "Epoch 10: loss=88702858677247076947059922562958317520828087742583359123803857407566846282974800106208739429212275754184381544916717323475289852612203802174212338058600255373297332426109969517949886232035531025661494288358077308500452341234366097609775071449296469115593014163421487142569455262309681017877692416.000, accuracy=0.999/0.999\n",
      "\n",
      "Final Test: final accuracy = 0.999\n"
     ]
    }
   ],
   "source": [
    "binary_classification_exec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43aaa4b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dd6007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03fd227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15d2597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
